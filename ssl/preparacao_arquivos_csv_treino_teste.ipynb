{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing training and test csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data list is:  ['Vilsel', 'Androm', 'Snarasite', 'MultiPlug', 'Hlux', 'VBA', 'Regrun', 'Injector', 'BrowseFox', 'Fasong', 'Allaple', 'Agent', 'Amonetize', 'Other', 'VBKrypt', 'HackKMS', 'Dinwod', 'Adposhel', 'Neshta', 'Autorun', 'InstallCore', 'Sality', 'Neoreklami', 'Stantinko', 'Elex', 'Expiro']\n"
     ]
    }
   ],
   "source": [
    "root_dir = r'../'\n",
    "images_dir = os.path.join(root_dir,'db','malevis_train')\n",
    "\n",
    "data_dir_list = os.listdir(images_dir)\n",
    "print ('the data list is: ',data_dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de classes:  26\n",
      "Classes mapeadas:  {'Vilsel': 0, 'Androm': 1, 'Snarasite': 2, 'MultiPlug': 3, 'Hlux': 4, 'VBA': 5, 'Regrun': 6, 'Injector': 7, 'BrowseFox': 8, 'Fasong': 9, 'Allaple': 10, 'Agent': 11, 'Amonetize': 12, 'Other': 13, 'VBKrypt': 14, 'HackKMS': 15, 'Dinwod': 16, 'Adposhel': 17, 'Neshta': 18, 'Autorun': 19, 'InstallCore': 20, 'Sality': 21, 'Neoreklami': 22, 'Stantinko': 23, 'Elex': 24, 'Expiro': 25}\n"
     ]
    }
   ],
   "source": [
    "# Assigning labels to each flower category\n",
    "num_classes = len(data_dir_list)\n",
    "labels_name = {}\n",
    "# Preenchendo o dicionário com a classe como chave e o índice como valor\n",
    "for idx, class_name in enumerate(data_dir_list):\n",
    "    labels_name[class_name] = idx\n",
    "    \n",
    "# Imprimindo o número de classes e o dicionário de mapeamento\n",
    "print(\"Número de classes: \", num_classes)\n",
    "print(\"Classes mapeadas: \", labels_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the images of dataset-Vilsel\n",
      "\n",
      "Read 350 images out of 350 images from data dir Vilsel\n",
      "\n",
      "Loading the images of dataset-Androm\n",
      "\n",
      "Read 350 images out of 350 images from data dir Androm\n",
      "\n",
      "Loading the images of dataset-Snarasite\n",
      "\n",
      "Read 350 images out of 350 images from data dir Snarasite\n",
      "\n",
      "Loading the images of dataset-MultiPlug\n",
      "\n",
      "Read 350 images out of 350 images from data dir MultiPlug\n",
      "\n",
      "Loading the images of dataset-Hlux\n",
      "\n",
      "Read 350 images out of 350 images from data dir Hlux\n",
      "\n",
      "Loading the images of dataset-VBA\n",
      "\n",
      "Read 350 images out of 350 images from data dir VBA\n",
      "\n",
      "Loading the images of dataset-Regrun\n",
      "\n",
      "Read 350 images out of 350 images from data dir Regrun\n",
      "\n",
      "Loading the images of dataset-Injector\n",
      "\n",
      "Read 350 images out of 350 images from data dir Injector\n",
      "\n",
      "Loading the images of dataset-BrowseFox\n",
      "\n",
      "Read 350 images out of 350 images from data dir BrowseFox\n",
      "\n",
      "Loading the images of dataset-Fasong\n",
      "\n",
      "Read 350 images out of 350 images from data dir Fasong\n",
      "\n",
      "Loading the images of dataset-Allaple\n",
      "\n",
      "Read 350 images out of 350 images from data dir Allaple\n",
      "\n",
      "Loading the images of dataset-Agent\n",
      "\n",
      "Read 350 images out of 350 images from data dir Agent\n",
      "\n",
      "Loading the images of dataset-Amonetize\n",
      "\n",
      "Read 350 images out of 350 images from data dir Amonetize\n",
      "\n",
      "Loading the images of dataset-Other\n",
      "\n",
      "Read 350 images out of 350 images from data dir Other\n",
      "\n",
      "Loading the images of dataset-VBKrypt\n",
      "\n",
      "Read 350 images out of 350 images from data dir VBKrypt\n",
      "\n",
      "Loading the images of dataset-HackKMS\n",
      "\n",
      "Read 350 images out of 350 images from data dir HackKMS\n",
      "\n",
      "Loading the images of dataset-Dinwod\n",
      "\n",
      "Read 350 images out of 350 images from data dir Dinwod\n",
      "\n",
      "Loading the images of dataset-Adposhel\n",
      "\n",
      "Read 350 images out of 350 images from data dir Adposhel\n",
      "\n",
      "Loading the images of dataset-Neshta\n",
      "\n",
      "Read 350 images out of 350 images from data dir Neshta\n",
      "\n",
      "Loading the images of dataset-Autorun\n",
      "\n",
      "Read 350 images out of 350 images from data dir Autorun\n",
      "\n",
      "Loading the images of dataset-InstallCore\n",
      "\n",
      "Read 350 images out of 350 images from data dir InstallCore\n",
      "\n",
      "Loading the images of dataset-Sality\n",
      "\n",
      "Read 350 images out of 350 images from data dir Sality\n",
      "\n",
      "Loading the images of dataset-Neoreklami\n",
      "\n",
      "Read 350 images out of 350 images from data dir Neoreklami\n",
      "\n",
      "Loading the images of dataset-Stantinko\n",
      "\n",
      "Read 350 images out of 350 images from data dir Stantinko\n",
      "\n",
      "Loading the images of dataset-Elex\n",
      "\n",
      "Read 350 images out of 350 images from data dir Elex\n",
      "\n",
      "Loading the images of dataset-Expiro\n",
      "\n",
      "Read 350 images out of 350 images from data dir Expiro\n",
      "\n",
      "Completed reading all the image files and assigned labels accordingly\n"
     ]
    }
   ],
   "source": [
    "# Criação dos DataFrames\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# Número de imagens para o conjunto de teste de cada categoria de malware\n",
    "num_images_for_test = 60\n",
    "\n",
    "# Loop sobre cada categoria de malware\n",
    "for dataset in data_dir_list:\n",
    "    # Carregar a lista de nomes de imagem em cada categoria\n",
    "    img_list = os.listdir(os.path.join(images_dir, dataset))\n",
    "    print('Loading the images of dataset-' + '{}\\n'.format(dataset))\n",
    "    label = labels_name[dataset]\n",
    "    num_img_files = len(img_list)\n",
    "    num_corrupted_files = 0\n",
    "    \n",
    "    # Certifique-se de que não tente amostrar mais imagens do que existem\n",
    "    num_images_for_test = min(num_images_for_test, num_img_files - 1)\n",
    "    test_list_index = random.sample(range(num_img_files), num_images_for_test)\n",
    "\n",
    "    # Ler cada arquivo\n",
    "    for i in range(num_img_files):\n",
    "        img_name = img_list[i]\n",
    "        img_filename = os.path.join(images_dir, dataset, img_name)\n",
    "        \n",
    "        try:\n",
    "            input_img = cv2.imread(img_filename)\n",
    "            if input_img is None:\n",
    "                raise ValueError(\"Image is None\")  # Lança erro se a imagem não puder ser lida\n",
    "            \n",
    "            if i in test_list_index:\n",
    "                test_data.append({'FileName': img_filename, 'Label': label, 'ClassName': dataset})\n",
    "            else:\n",
    "                train_data.append({'FileName': img_filename, 'Label': label, 'ClassName': dataset})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'{img_filename} is corrupted or not readable: {e}\\n')\n",
    "            num_corrupted_files += 1\n",
    "    \n",
    "    print('Read {0} images out of {1} images from data dir {2}\\n'.format(num_img_files - num_corrupted_files, num_img_files, dataset))\n",
    "\n",
    "# Criação dos DataFrames finais\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print('Completed reading all the image files and assigned labels accordingly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório /home/ivo/data/Studys/Electric/TCC/Code/ssl/dataset/annotations criado com sucesso!\n",
      "The train and test csv files are saved\n"
     ]
    }
   ],
   "source": [
    "dest_path = os.path.join(os.getcwd(), 'dataset', 'annotations')\n",
    "\n",
    "if not os.path.exists(dest_path):\n",
    "    try:\n",
    "        os.makedirs(dest_path, exist_ok=True)\n",
    "        print(f\"Diretório {dest_path} criado com sucesso!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar diretório: {e}\")\n",
    "else:\n",
    "    print(f\"Diretório {dest_path} já existe.\")\n",
    "\n",
    "train_df.to_csv(os.path.join(dest_path,'malevis_recognition_train.csv'))\n",
    "test_df.to_csv(os.path.join(dest_path,'malevis_recognition_test.csv'))\n",
    "print('Os arquivos csv de treino e teste foram criados com sucesso.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
